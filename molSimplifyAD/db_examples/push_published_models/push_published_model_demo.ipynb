{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model, model_from_json\n",
    "import sklearn.preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, r2_score, mean_absolute_error\n",
    "from molSimplifyAD.utils.pymongo_tools import connect2db, push_models_published\n",
    "from molSimplifyAD.mlclass_mongo import modelPublished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = '/home/crduan/Package/molSimplify/molSimplify/tf_nn/homolumo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if your model is a directly saved by model.save()\n",
    "# model = load_model(basepath+'homo_empty_model.h5')\n",
    "\n",
    "### if you save you model via json.\n",
    "with open(basepath+'gap_model.json', 'r') as fo:\n",
    "    loaded_model_json = fo.read()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights(basepath+'gap_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train/test information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For JP's old models\n",
    "# df_train = pd.read_csv(basepath+\"ls_ii_bl_x.csv\")\n",
    "# y_train = pd.read_csv(basepath+\"ls_ii_bl_y.csv\").values\n",
    "# # n_train = pd.read_csv(basepath+\"train_names.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(basepath+\"gap_train_x.csv\")\n",
    "df_test = pd.read_csv(basepath+\"gap_test_x.csv\")\n",
    "y_train = pd.read_csv(basepath+\"gap_train_y.csv\").values\n",
    "y_test = pd.read_csv(basepath+\"gap_test_y.csv\").values\n",
    "n_train = pd.read_csv(basepath+\"gap_train_names.csv\").values\n",
    "n_test = pd.read_csv(basepath+\"gap_test_names.csv\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basepath+\"gap_vars.csv\", \"r\") as fo:\n",
    "    features = fo.readlines()\n",
    "features =[f.split(\"\\n\")[0].strip('\\r') for f in features]\n",
    "target = \"energeticgap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1373, 3), (1373, 154))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames, el = [], []\n",
    "for f in df_train:\n",
    "    std = np.std(df_train[str(f)].dropna().values)\n",
    "    if std > 1e-6:\n",
    "        fnames.append(f)\n",
    "    else:\n",
    "        el.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[fnames].values\n",
    "X_test = df_test[fnames].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = sklearn.preprocessing.StandardScaler()\n",
    "x_scaler.fit(X_train)\n",
    "_X_train = x_scaler.transform(X_train)\n",
    "_X_test = x_scaler.transform(X_test)\n",
    "y_scaler= sklearn.preprocessing.StandardScaler()\n",
    "### Use if regression\n",
    "y_scaler.fit(y_train)\n",
    "_y_train = y_scaler.transform(y_train)\n",
    "_y_test = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hat_y_train = y_scaler.inverse_transform(model.predict(_X_train))\n",
    "hat_y_test = y_scaler.inverse_transform(model.predict(_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for classifiers\n",
    "# metrics = {\"auc\": roc_auc_score(y_test.reshape(-1,), hat_y_test.reshape(-1,))}\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.2184421238081002, 'r2': 0.9445827830350787}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = {\"r2\": r2_score(y_test.reshape(-1,), hat_y_test.reshape(-1,)),\n",
    "          \"mae\": mean_absolute_error(y_test.reshape(-1,), hat_y_test.reshape(-1,))}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble model_dict (prepare your push)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## For JP's old models\n",
    "# model_dict = {\n",
    "#     \"publication\": \"JP_JPCA_2017\",\n",
    "#     \"doi\": \"10.1021/acs.jpca.7b08750\",\n",
    "#     \"features\": features,\n",
    "#     \"target\": target,\n",
    "#     \"name_train\": False,\n",
    "#     \"X_train\": [X_train[ii].tolist() for ii in range(X_train.shape[0])],\n",
    "#     \"target_train\": [y_train[ii].tolist() for ii in range(y_train.shape[0])],\n",
    "#     \"name_test\": False,\n",
    "#     \"X_test\": False,\n",
    "#     \"target_test\": False,\n",
    "#     \"x_scaler\": pickle.dumps(x_scaler),\n",
    "#     \"y_scaler\": pickle.dumps(y_scaler),\n",
    "#     \"metrics\": False\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-d710d4af7299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m\"X_train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"target_train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m\"name_test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;34m\"X_test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m\"target_test\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    \"publication\": \"Nandy_IECR_2018\",\n",
    "    \"doi\": \"10.1021/acs.iecr.8b04015\",\n",
    "    \"features\": features,\n",
    "    \"target\": target,\n",
    "    \"name_train\": [n_train[ii].tolist() for ii in range(n_train.shape[0])],\n",
    "    \"X_train\": [X_train[ii].tolist() for ii in range(X_train.shape[0])],\n",
    "    \"target_train\": [y_train[ii].tolist() for ii in range(y_train.shape[0])],\n",
    "    \"name_test\": [n_test[ii].tolist() for ii in range(n_test.shape[0])],\n",
    "    \"X_test\": [X_test[ii].tolist() for ii in range(X_test.shape[0])],\n",
    "    \"target_test\": [y_test[ii].tolist() for ii in range(y_test.shape[0])],\n",
    "    \"x_scaler\": pickle.dumps(x_scaler),\n",
    "    \"y_scaler\": pickle.dumps(y_scaler),\n",
    "    \"metrics\": metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "dbconfig = json.load(open(home + \"/.db_config\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pushing...\n",
      "Dumping database....\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "push_models_published(model, model_dict,\n",
    "                      database='tmc', collection='published_models',\n",
    "                      user=dbconfig['user'], pwd=dbconfig['pwd'],\n",
    "                      host=\"localhost\", port=27017, auth=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test whether your push is successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = connect2db(user=dbconfig['user'], pwd=dbconfig['pwd'],\n",
    "                host=\"localhost\", port=27017,\n",
    "                database='tmc', auth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crduan/.conda/envs/mols_keras/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.published_models.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mols_keras] *",
   "language": "python",
   "name": "conda-env-.conda-mols_keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
